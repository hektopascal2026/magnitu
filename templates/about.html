{% extends "layout.html" %}
{% block title %}About — Magnitu{% endblock %}

{% block content %}
<div class="dashboard-section">
    <h2>How Magnitu Learns</h2>
    <p class="section-desc">Magnitu is your personal relevance engine. It watches what you care about and learns to separate signal from noise — so the important stories float to the top.</p>
</div>

<!-- What Changed in Magnitu 2 -->
<div class="dashboard-section">
    <h2>What Changed in Magnitu 2</h2>
    <p class="section-desc">
        Magnitu 2 replaces the text-matching engine with a language model that actually understands what articles are about. Here's the difference:
    </p>

    <div class="about-section">
        <h3>Magnitu 1 — Word Counting</h3>
        <p>The original version used <strong>TF-IDF + Logistic Regression</strong>. It worked like this:</p>
        <div class="about-detail-grid">
            <div class="about-detail">
                <span class="about-detail-label">How it read text</span>
                <span class="about-detail-value">Counted how often each word appeared (TF-IDF). A bag of words — no understanding of order or meaning.</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">What it learned</span>
                <span class="about-detail-value">Which words correlate with each label. "investigation" → investigation lead, "press release" → noise.</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Limitation</span>
                <span class="about-detail-value">"Not relevant" and "very relevant" looked similar because both contain "relevant". It couldn't understand negation, context, or synonyms.</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Languages</span>
                <span class="about-detail-value">Treated each language separately. German and English articles about the same topic looked completely different to the model.</span>
            </div>
        </div>
    </div>

    <div class="about-section">
        <h3>Magnitu 2 — Language Understanding</h3>
        <p>The new version uses <strong>DistilRoBERTa</strong>, a pre-trained language model with 82 million parameters that has read billions of words of text. It understands language before it ever sees your labels.</p>
        <div class="about-detail-grid">
            <div class="about-detail">
                <span class="about-detail-label">How it reads text</span>
                <span class="about-detail-value">Converts each article into a 768-dimensional "meaning vector" that captures what the article is about — not just which words appear.</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">What it learns</span>
                <span class="about-detail-value">Which types of meaning correlate with each label. It recognises that "Untersuchung" and "investigation" mean the same thing, that "no evidence of wrongdoing" is different from "evidence of wrongdoing".</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Why it's better</span>
                <span class="about-detail-value">Transfer learning: the model already knows what words mean before you label a single entry. Your labels teach it what matters <em>to you</em>, not what words mean in general.</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Still fast</span>
                <span class="about-detail-value">The language model runs once per article when you sync. After that, scoring uses cached vectors + a simple classifier — just as fast as before.</span>
            </div>
        </div>
    </div>

    <div class="about-section">
        <h3>Reasoning Labels (New)</h3>
        <p>When you label an entry, you can now add a short explanation — especially useful for investigation leads. Something like <em>"links politician X to company Y through public contracts"</em>. These reasoning notes:</p>
        <div class="about-detail-grid">
            <div class="about-detail">
                <span class="about-detail-label">Improve the recipe</span>
                <span class="about-detail-value">Key phrases from your reasoning are boosted in the keyword recipe that Seismo uses for scoring.</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Help your memory</span>
                <span class="about-detail-value">Six months from now, you'll remember why you flagged something as an investigation lead.</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Stay optional</span>
                <span class="about-detail-value">You never have to write reasoning. Labeling is just as fast as before — the text field is there when you have something to say.</span>
            </div>
        </div>
    </div>

    <div class="about-section">
        <h3>How the Recipe Still Works</h3>
        <p>Seismo's PHP scoring engine hasn't changed. It still evaluates a keyword-weight recipe. What changed is how that recipe is built:</p>
        <div class="about-detail-grid">
            <div class="about-detail">
                <span class="about-detail-label">Magnitu 1</span>
                <span class="about-detail-value">Recipe extracted directly from the TF-IDF model's word weights.</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Magnitu 2</span>
                <span class="about-detail-value">The transformer scores all entries. A TF-IDF "student" model learns from the transformer's predictions. The recipe is extracted from the student. Same format — but the keywords now reflect the transformer's deeper understanding.</span>
            </div>
        </div>
        <p>This is called <strong>knowledge distillation</strong> — compressing the transformer's intelligence into a lightweight recipe that PHP can run in milliseconds.</p>
    </div>
</div>

<!-- The Loop -->
<div class="dashboard-section">
    <h2>The Learning Loop</h2>
    <div class="about-steps">
        <div class="about-step">
            <div class="about-step-number">1</div>
            <div class="about-step-body">
                <h3>Sync</h3>
                <p>Pull new entries from Seismo. {% if architecture == 'transformer' %}Each entry is processed through the language model to create a meaning vector. This happens during sync so everything else stays instant.{% else %}Everything lands in a local queue for you to review.{% endif %}</p>
            </div>
        </div>
        <div class="about-step">
            <div class="about-step-number">2</div>
            <div class="about-step-body">
                <h3>Label</h3>
                <p>You read entries and assign one of four labels. Optionally add a reasoning note explaining why. Each label is a training example that teaches the model what matters to you.</p>
                <div class="about-labels-grid">
                    <span class="label-dist-item label-investigation_lead">Investigation Lead</span>
                    <span class="label-dist-item label-important">Important</span>
                    <span class="label-dist-item label-background">Background</span>
                    <span class="label-dist-item label-noise">Noise</span>
                </div>
            </div>
        </div>
        <div class="about-step">
            <div class="about-step-number">3</div>
            <div class="about-step-body">
                <h3>Train</h3>
                <p>Hit <strong>Train</strong> and Magnitu builds a new model from all your labels. {% if architecture == 'transformer' %}The classifier learns which patterns in the meaning vectors predict each category.{% else %}It learns which words, phrases, and sources predict each category.{% endif %} Minimum {{ config.min_labels_to_train or 20 }} labels to start; more labels = better accuracy.</p>
            </div>
        </div>
        <div class="about-step">
            <div class="about-step-number">4</div>
            <div class="about-step-body">
                <h3>Score &amp; Push</h3>
                <p>The model scores every entry with a relevance number (0–100) and a predicted label. {% if architecture == 'transformer' %}A keyword recipe is distilled via knowledge distillation and pushed to Seismo so the main feed sorts by relevance.{% else %}Push to Seismo so the main feed can sort by relevance.{% endif %}</p>
            </div>
        </div>
        <div class="about-step">
            <div class="about-step-number">5</div>
            <div class="about-step-body">
                <h3>Review &amp; Correct</h3>
                <p>Check the <strong>Top 30</strong> page to see what the model thinks is most important. Reclassify anything it got wrong — these corrections are the highest-signal training data you can give it.</p>
            </div>
        </div>
    </div>
</div>

<!-- Under the Hood -->
<div class="dashboard-section">
    <h2>Under the Hood</h2>

    {% if architecture == 'transformer' %}
    <div class="about-section">
        <h3>The Language Model</h3>
        <p>Magnitu 2 uses <strong>DistilRoBERTa</strong> (via PyTorch + HuggingFace Transformers) to convert article text into 768-dimensional embedding vectors. A <strong>Logistic Regression</strong> classifier then maps these vectors to your four labels.</p>
        <div class="about-detail-grid">
            <div class="about-detail">
                <span class="about-detail-label">Base model</span>
                <span class="about-detail-value">{{ config.transformer_model_name or 'distilroberta-base' }} (82M parameters, 6 transformer layers)</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Embedding</span>
                <span class="about-detail-value">768-dimensional vector per article, computed once at sync time</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Classifier</span>
                <span class="about-detail-value">Logistic Regression on cached embeddings — training takes seconds</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Device</span>
                <span class="about-detail-value">Auto-detected: Apple Silicon (MPS), NVIDIA GPU (CUDA), or CPU</span>
            </div>
        </div>
    </div>
    {% else %}
    <div class="about-section">
        <h3>The Classifier</h3>
        <p>Magnitu uses a <strong>Logistic Regression</strong> model (via scikit-learn) with TF-IDF text features and one-hot encoded source types. It's fast to train, interpretable, and works well with hundreds of labels — no GPU required.</p>
        <div class="about-detail-grid">
            <div class="about-detail">
                <span class="about-detail-label">Text features</span>
                <span class="about-detail-value">TF-IDF, up to 10k unigrams + bigrams</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Structured features</span>
                <span class="about-detail-value">Source type (RSS, Substack, Email, Lex EU/CH)</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Class balancing</span>
                <span class="about-detail-value">Balanced weights — rare classes aren't drowned out</span>
            </div>
        </div>
    </div>
    {% endif %}

    <div class="about-section">
        <h3>The Recipe</h3>
        <p>After training, Magnitu <strong>distills</strong> the model into a lightweight keyword-weight recipe (JSON). This recipe is pushed to Seismo so it can do basic scoring in PHP without needing Python.{% if architecture == 'transformer' %} In transformer mode, a TF-IDF "student" model is trained on the transformer's predictions, and the recipe is extracted from the student — this is called <strong>knowledge distillation</strong>.{% endif %}</p>
    </div>

    <div class="about-section">
        <h3>The Relevance Score</h3>
        <p>Each entry gets a composite score from 0 to 100, calculated from the model's class probabilities:</p>
        <div class="about-detail-grid">
            <div class="about-detail">
                <span class="about-detail-label">Investigation Lead</span>
                <span class="about-detail-value">weight 1.0 (highest)</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Important</span>
                <span class="about-detail-value">weight 0.66</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Background</span>
                <span class="about-detail-value">weight 0.33</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Noise</span>
                <span class="about-detail-value">weight 0.0</span>
            </div>
        </div>
        <p>So an entry the model is 80% sure is an Investigation Lead scores ~80, while one it thinks is pure Noise scores ~0.</p>
    </div>
</div>

<!-- Smart Sampling -->
<div class="dashboard-section">
    <h2>Smart Labeling Queue</h2>
    <p class="section-desc">Once a model exists, the labeling page doesn't just show the newest entries. It uses active learning strategies to surface the entries that will improve the model fastest.</p>

    <div class="about-sampling-grid">
        <div class="about-sampling-item">
            <span class="sampling-pill sampling-pill-uncertain" style="display:inline-block; margin-bottom:6px;">Uncertain</span>
            <p>Entries where the model can't decide — its probability distribution is flat across classes. Labeling these resolves the model's biggest confusions.</p>
        </div>
        <div class="about-sampling-item">
            <span class="sampling-pill sampling-pill-conflict" style="display:inline-block; margin-bottom:6px;">Conflict</span>
            <p>Entries where the full ML model and the lightweight recipe disagree on the predicted label. These reveal where the recipe approximation breaks down.</p>
        </div>
        <div class="about-sampling-item">
            <span class="sampling-pill sampling-pill-diverse" style="display:inline-block; margin-bottom:6px;">Diverse</span>
            <p>Entries from source categories that are underrepresented in your labels. If you've labeled 100 tech stories but 0 from local government, it surfaces one to broaden the model's horizons.</p>
        </div>
        <div class="about-sampling-item">
            <span class="sampling-pill sampling-pill-new" style="display:inline-block; margin-bottom:6px;">New</span>
            <p>The newest unlabeled entries — keeps the feed fresh and ensures recent content gets reviewed.</p>
        </div>
    </div>
</div>

<!-- Model Profiles -->
<div class="dashboard-section">
    <h2>Model Profiles</h2>
    <p class="section-desc">Every Magnitu instance runs a named model profile. Models are portable — you can export, share, and import them.</p>

    <div class="about-section">
        <h3>The .magnitu File</h3>
        <p>A model is packaged as a <code>.magnitu</code> file — a zip archive containing everything needed to continue training:</p>
        <div class="about-detail-grid">
            <div class="about-detail">
                <span class="about-detail-label">manifest.json</span>
                <span class="about-detail-value">Model name, UUID, description, version chain, metrics, architecture</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">model.joblib</span>
                <span class="about-detail-value">{% if architecture == 'transformer' %}Classifier head (tiny — the base transformer is downloaded from HuggingFace){% else %}Trained sklearn pipeline (works immediately after import){% endif %}</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">recipe.json</span>
                <span class="about-detail-value">Distilled keyword recipe for Seismo's PHP scorer</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">labels.json</span>
                <span class="about-detail-value">All labeled entries with text and reasoning notes — the training data</span>
            </div>
        </div>
    </div>

    <div class="about-section">
        <h3>Sharing and Collaboration</h3>
        <p>Export your model from the <strong>Model</strong> page and send the <code>.magnitu</code> file to a colleague. They import it, get all your labels and the trained model, then continue labeling and retraining. Each training creates a new version in the chain.</p>
    </div>

    <div class="about-section">
        <h3>Version Protection</h3>
        <p>When importing a model file, Magnitu protects against regression:</p>
        <div class="about-detail-grid">
            <div class="about-detail">
                <span class="about-detail-label">Labels</span>
                <span class="about-detail-value">Always merged — newer timestamp wins on conflicts</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Trained model</span>
                <span class="about-detail-value">Only loaded if the imported version is higher than your local version</span>
            </div>
            <div class="about-detail">
                <span class="about-detail-label">Older import</span>
                <span class="about-detail-value">Labels are still imported, but the trained model is skipped — retrain to incorporate new labels</span>
            </div>
        </div>
        <p>This means you can never accidentally overwrite a better model with an older one.</p>
    </div>
</div>

<!-- Tips -->
<div class="dashboard-section">
    <h2>Tips for Faster Learning</h2>
    <div class="about-tips">
        <div class="about-tip">
            <strong>Label consistently.</strong> If two similar articles should be "Important", label them both "Important". The model learns from patterns in your choices.
        </div>
        <div class="about-tip">
            <strong>Add reasoning for investigation leads.</strong> A short note like "links X to Y" helps the recipe and helps you remember why later.
        </div>
        <div class="about-tip">
            <strong>Correct the Top 30.</strong> When the model is confidently wrong, that correction teaches it more than 10 random labels.
        </div>
        <div class="about-tip">
            <strong>Retrain often.</strong> After every ~10 new labels, hit Train to incorporate your latest feedback. Each version builds on all previous labels.
        </div>
        <div class="about-tip">
            <strong>Don't skip the "boring" ones.</strong> Labeling Noise and Background entries is just as valuable as labeling Investigation Leads — the model needs to know what to filter out.
        </div>
        <div class="about-tip">
            <strong>Check the Dashboard.</strong> Watch accuracy and F1 score climb across model versions. If a class has very few labels, focus your next session on it.
        </div>
    </div>
</div>

<!-- Keyboard Shortcuts -->
<div class="dashboard-section">
    <h2>Keyboard Shortcuts (Label Page)</h2>
    <div class="shortcuts-grid">
        <span class="shortcut"><kbd>1</kbd> Investigation Lead</span>
        <span class="shortcut"><kbd>2</kbd> Important</span>
        <span class="shortcut"><kbd>3</kbd> Background</span>
        <span class="shortcut"><kbd>4</kbd> Noise</span>
        <span class="shortcut"><kbd>r</kbd> Focus reasoning field</span>
        <span class="shortcut"><kbd>Esc</kbd> Exit reasoning field</span>
        <span class="shortcut"><kbd>j</kbd> / <kbd>&darr;</kbd> Next card</span>
        <span class="shortcut"><kbd>k</kbd> / <kbd>&uarr;</kbd> Previous card</span>
        <span class="shortcut"><kbd>u</kbd> Undo label</span>
    </div>
</div>
{% endblock %}
